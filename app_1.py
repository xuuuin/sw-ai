import streamlit as st
import cv2
import time
import pygame
import numpy as np
import mediapipe as mp
import math
import base64
import os

# Base64 íŒŒì¼ ê²½ë¡œ ì„¤ì •
# Base64 ë°ì´í„°ê°€ ì €ì¥ëœ íŒŒì¼ ì´ë¦„ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”.
# (ì˜ˆ: 'alarm_b64.txt'ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
ALARM_FILE_PATH = "alarm_b64.txt" 
ALARM_WAV_FILENAME = "alarm.wav"

# ========================
# 1. Pygame ì´ˆê¸°í™” & ì•ŒëŒ
# ========================
def decode_alarm_sound(file_path, output_filename):
    """Base64 íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì™€ WAV íŒŒì¼ë¡œ ë””ì½”ë”©"""
    try:
        with open(file_path, "r") as f:
            b64_data = f.read().strip()
        
        # íŒŒì¼ì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬
        if not b64_data:
            st.error(f"'{file_path}' íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. Base64 ë¬¸ìì—´ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False

        decoded_data = base64.b64decode(b64_data)
        with open(output_filename, "wb") as f:
            f.write(decoded_data)
        return True
    except FileNotFoundError:
        st.error(f"ì•ŒëŒ íŒŒì¼ '{file_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Base64 íŒŒì¼ì„ ë§Œë“¤ê³  ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
        return False
    except Exception as e:
        st.error(f"Base64 ë””ì½”ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

# Base64 ë””ì½”ë”© ë° Pygame ì´ˆê¸°í™”
if decode_alarm_sound(ALARM_FILE_PATH, ALARM_WAV_FILENAME):
    try:
        pygame.mixer.init()
        # ì£¼ì˜: Streamlitì€ ë©€í‹°ìŠ¤ë ˆë”© í™˜ê²½ì—ì„œ ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
        # ì›¹ìº ê³¼ Pygameì„ ë™ì‹œì— ì‹¤í–‰í•  ë•Œ ê°„í—ì ì¸ ì¶©ëŒì´ë‚˜ ì§€ì—°ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # Streamlit Cloud í™˜ê²½ì—ì„œëŠ” Pygameì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ALARM_SOUND = pygame.mixer.Sound(ALARM_WAV_FILENAME)
    except pygame.error as e:
        st.error(f"Pygame ì‚¬ìš´ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        # Pygame ì‹¤íŒ¨í•´ë„ ì›¹ìº  ëª¨ë‹ˆí„°ë§ì€ ê³„ì†ë˜ë„ë¡ st.stop()ì€ ì œê±°
else:
    # ì•ŒëŒ íŒŒì¼ì´ ì—†ì–´ë„ ì•± ì‹¤í–‰ì€ ê³„ì†ë˜ë„ë¡ ì²˜ë¦¬ (ë‹¨, ì•ŒëŒì€ ìš¸ë¦¬ì§€ ì•ŠìŒ)
    pass


# ì•ŒëŒ ë° ë³¼ë¥¨ ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
alarm_playing = False
last_alarm_time = 0.0
ALARM_INTERVAL = 1
BASE_VOLUME = 0.3  # ìµœì†Œ ë³¼ë¥¨
MAX_VOLUME = 1.0   # ìµœëŒ€ ë³¼ë¥¨ (pygame ë³¼ë¥¨ì€ 0.0 ~ 1.0)
RAMP_DURATION = 2.0  # ë³¼ë¥¨ì´ ìµœëŒ€ì¹˜ì— ë„ë‹¬í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„(ì´ˆ)

def play_alarm(now, eyes_closed_time, EYE_CLOSED_TIME_SEC):
    """
    ëˆˆ ê°ì€ ì‹œê°„ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë³¼ë¥¨ì„ í‚¤ìš´ë‹¤.
    eyes_closed_time: ëˆˆ ê°ê³  ìˆëŠ” ëˆ„ì  ì‹œê°„ (ì´ˆ)
    """
    global last_alarm_time, alarm_playing
    
    # Pygame ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ALARM_SOUND ê°ì²´ê°€ ì—†ìœ¼ë©´ ì¬ìƒ ì‹œë„í•˜ì§€ ì•ŠìŒ
    if 'ALARM_SOUND' not in globals():
        return

    # ì¡¸ìŒ ê¸°ì¤€(EYE_CLOSED_TIME_SEC) ì´í›„ë¶€í„° ì¦ê°€ë¶„ ê³„ì‚°
    extra = max(0.0, eyes_closed_time - EYE_CLOSED_TIME_SEC)
    ratio = min(1.0, extra / RAMP_DURATION)
    volume = BASE_VOLUME + (MAX_VOLUME - BASE_VOLUME) * ratio
    volume = max(0.0, min(1.0, volume)) 

    if now - last_alarm_time >= ALARM_INTERVAL:
        ALARM_SOUND.stop()
        ALARM_SOUND.set_volume(volume)
        ALARM_SOUND.play()
        last_alarm_time = now
        alarm_playing = True

def stop_alarm():
    global alarm_playing
    if 'ALARM_SOUND' in globals() and alarm_playing:
        ALARM_SOUND.stop()
        alarm_playing = False

# ========================
# 2. MediaPipe ì¤€ë¹„ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
# ========================
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils

LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]

def calc_EAR(landmarks, eye_idx_list, img_w, img_h):
    """ëˆˆ ëœë“œë§ˆí¬ ì¢Œí‘œë¡œ EAR ê³„ì‚°"""
    points = []
    for idx in eye_idx_list:
        lm = landmarks[idx]
        x = int(lm.x * img_w)
        y = int(lm.y * img_h)
        points.append((x, y))
    p1, p2, p3, p4, p5, p6 = points

    def dist(a, b):
        return math.hypot(a[0] - b[0], a[1] - b[1])

    # EAR ê³µì‹: (ìˆ˜ì§ê±°ë¦¬1 + ìˆ˜ì§ê±°ë¦¬2) / (2 * ìˆ˜í‰ê±°ë¦¬)
    ear = (dist(p2, p6) + dist(p3, p5)) / (2.0 * dist(p1, p4) + 1e-6)
    return ear, points

# ========================
# 3. Streamlit UI & ë©”ì¸ ë£¨í”„ 
# ========================

st.set_page_config(layout="wide")

# CSS for centering and full screen (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
st.markdown("""
    <style>
    /* Streamlit ë©”ì¸ ë¸”ë¡ì„ ì¤‘ì•™ì— ë°°ì¹˜ ë° ë„“ì€ ë ˆì´ì•„ì›ƒ í™œìš© */
    .block-container {
        padding-top: 2rem !important;
        padding-bottom: 2rem !important;
    }
    /* í…ìŠ¤íŠ¸ ì…ë ¥ ì¤‘ì•™ ì •ë ¬ */
    .stTextInput > div > div > input {
        text-align: center;
        font-size: 1.5rem;
        padding: 10px;
        width: 100%;
    }
    /* ë¼ë””ì˜¤ ë²„íŠ¼ ì¤‘ì•™ ì •ë ¬ */
    .stRadio > label {
        justify-content: center;
    }
    /* ë²„íŠ¼ í¬ê¸° ë° í°íŠ¸ ì„¤ì • */
    .stButton > button {
        width: 150px;
        height: 50px;
        font-size: 1.2rem;
        margin: 10px;
    }
    /* ëª©í‘œ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
    .study-goal {
        font-size: 2.5rem;
        font-weight: bold;
        color: #4CAF50;
        margin-bottom: 20px;
        text-align: center;
    }
    /* ë©”ì¸ íƒ€ì´ë¨¸ ìŠ¤íƒ€ì¼ */
    .main-timer {
        font-size: 5rem;
        font-weight: bold;
        color: #f44336;
        margin-bottom: 20px;
        text-align: center;
    }
    /* í‘¸í„° ìŠ¤íƒ€ì¼ */
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background-color: #f1f1f1;
        color: black;
        text-align: center;
        padding: 10px;
        font-size: 0.8rem;
    }
    </style>
""", unsafe_allow_html=True)


if 'study_started' not in st.session_state:
    st.session_state.study_started = False
if 'study_goal' not in st.session_state:
    st.session_state.study_goal = ""
if 'EYE_CLOSED_TIME_SEC' not in st.session_state:
    st.session_state.EYE_CLOSED_TIME_SEC = 3.0
if 'study_session_start_time' not in st.session_state:
    st.session_state.study_session_start_time = 0.0
if 'focused_time' not in st.session_state:
    st.session_state.focused_time = 0.0
if 'drowsy_time' not in st.session_state:
    st.session_state.drowsy_time = 0.0
if 'is_paused' not in st.session_state:
    st.session_state.is_paused = False
if 'total_elapsed_time' not in st.session_state:
    st.session_state.total_elapsed_time = 0.0


def format_time(sec):
    m = int(sec // 60)
    s = int(sec % 60)
    return f"{m:02d}:{s:02d}"

if not st.session_state.study_started:
    # --- ì„¤ì • í™”ë©´ ---
    st.markdown("<h2 style='text-align: center;'>ì˜¤ëŠ˜ì˜ ê³µë¶€ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?</h2>", unsafe_allow_html=True)
    study_goal_input = st.text_input("", placeholder="ì˜ˆ: Streamlit ì•± ê°œë°œ, ì„ í˜•ëŒ€ìˆ˜í•™ ë³µìŠµ")

    st.markdown("<h3 style='text-align: center;'>ì§‘ì¤‘ ëª¨ë“œ(ì¡¸ìŒ ê°ì§€ ë¯¼ê°ë„)ë¥¼ ì„ íƒí•˜ì„¸ìš”.</h3>", unsafe_allow_html=True)
    sensitivity_options = {
        "1ë‹¨ê³„ (í”¼ê³¤í•´ìš”): ëˆˆ ê°ìŒ 5ì´ˆ í—ˆìš© (ëŠìŠ¨í•œ ê°ì§€)": 5.0,
        "2ë‹¨ê³„ (ë³´í†µì´ì—ìš”): ëˆˆ ê°ìŒ 3ì´ˆ í—ˆìš© (ê¸°ë³¸)": 3.0,
        "3ë‹¨ê³„ (ì§‘ì¤‘í• ë˜ìš”): ëˆˆ ê°ìŒ 2ì´ˆ í—ˆìš© (ì—„ê²©)": 2.0,
        "4ë‹¨ê³„ (ìŠ¤íŒŒë¥´íƒ€): ëˆˆ ê¹œë¹¡ì„ì´ ëŠë ¤ì§€ê¸°ë§Œ í•´ë„ ê²½ê³  (ì´ˆê³ ê°•ë„)": 0.5,
    }
    selected_option = st.radio(
        "",
        list(sensitivity_options.keys()),
        index=1,
        key="sensitivity_radio"
    )

    if st.button("ê³µë¶€ ì‹œì‘", key="start_study_button"):
        if study_goal_input:
            st.session_state.study_goal = study_goal_input
            st.session_state.EYE_CLOSED_TIME_SEC = sensitivity_options[selected_option]
            st.session_state.study_started = True
            st.session_state.study_session_start_time = time.time()
            st.session_state.focused_time = 0.0
            st.session_state.drowsy_time = 0.0
            st.session_state.is_paused = False
            st.session_state.total_elapsed_time = 0.0
            st.rerun()
        else:
            st.warning("ê³µë¶€ ëª©í‘œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
else:
    # --- í•™ìŠµ ì§„í–‰ í™”ë©´ ---
    st.markdown(f"<p class='study-goal'>{st.session_state.study_goal}</p>", unsafe_allow_html=True)

    study_timer_placeholder = st.empty()
    webcam_placeholder = st.empty()
    status_placeholder = st.empty()

    col1, col2, col3 = st.columns([1, 1, 1])

    with col1:
        if st.button("ì ì‹œ ë©ˆì¶¤" if not st.session_state.is_paused else "ë‹¤ì‹œ ì‹œì‘", key="pause_button"):
            st.session_state.is_paused = not st.session_state.is_paused
            stop_alarm()
            if not st.session_state.is_paused:
                # ë©ˆì¶¤ ì‹œê°„ë§Œí¼ ì‹œì‘ ì‹œê°„ ë³´ì •
                st.session_state.study_session_start_time = time.time() - st.session_state.total_elapsed_time
            st.rerun()

    with col3:
        if st.button("ê³µë¶€ ì¢…ë£Œ", key="end_study_button"):
            stop_alarm()
            st.session_state.study_started = False
            st.session_state.is_paused = True 
            st.rerun()

    # ì›¹ìº  ì²˜ë¦¬
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        st.error("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš© ì¤‘ì´ ì•„ë‹Œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        if st.session_state.total_elapsed_time > 0:
            st.button("í†µê³„ ë³´ê¸°/ì¢…ë£Œ", on_click=lambda: st.session_state.update(study_started=False, is_paused=True))
        st.stop()

    eyes_closed_time = 0.0
    no_face_time = 0.0
    prev_time = time.time()
    
    with mp_face_mesh.FaceMesh(
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    ) as face_mesh:
        while st.session_state.study_started:
            if st.session_state.is_paused:
                study_timer_placeholder.markdown(f"<p class='main-timer'>{format_time(st.session_state.total_elapsed_time)}</p>", unsafe_allow_html=True)
                
                # Paused UI
                ret, frame = cap.read()
                if ret:
                    frame = cv2.flip(frame, 1)
                    h, w, _ = frame.shape
                    
                    # ë°˜íˆ¬ëª… ê²€ì€ìƒ‰ ì˜¤ë²„ë ˆì´ (ì›¹ìº  í™”ë©´ ìœ„ì— ì–´ë‘¡ê²Œ í‘œì‹œ)
                    overlay = frame.copy()
                    cv2.rectangle(overlay, (0, 0), (w, h), (0, 0, 0), -1)
                    alpha = 0.7
                    combined_frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)

                    # í…ìŠ¤íŠ¸
                    cv2.putText(combined_frame, "PAUSED", (w // 2 - 150, h // 2), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 3, cv2.LINE_AA)
                    
                    # ê²½ê³  ì œê±°: use_column_width -> use_container_width
                    webcam_placeholder.image(combined_frame, channels="BGR", use_container_width=True)
                
                status_placeholder.text("ì¼ì‹œ ì •ì§€ë¨")
                time.sleep(0.1)
                continue

            now = time.time()
            dt = now - prev_time
            prev_time = now

            st.session_state.total_elapsed_time = now - st.session_state.study_session_start_time
            study_timer_placeholder.markdown(f"<p class='main-timer'>{format_time(st.session_state.total_elapsed_time)}</p>", unsafe_allow_html=True)


            ret, frame = cap.read()
            if not ret:
                time.sleep(0.1)
                continue

            frame = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            img_h, img_w, _ = frame.shape
            results = face_mesh.process(rgb)

            face_detected = False
            eyes_open = False
            current_ear = 0.0
            
            # --- ì¡¸ìŒ/ìë¦¬ë¹„ì›€ ê°ì§€ ë¡œì§ ---
            if results.multi_face_landmarks:
                face_detected = True
                no_face_time = 0.0

                face_landmarks = results.multi_face_landmarks[0].landmark
                left_ear, left_points = calc_EAR(face_landmarks, LEFT_EYE_IDX, img_w, img_h)
                right_ear, right_points = calc_EAR(face_landmarks, RIGHT_EYE_IDX, img_w, img_h)
                current_ear = (left_ear + right_ear) / 2.0

                # ëˆˆ ì£¼ë³€ ì  ì°ê¸°
                for (x, y) in left_points + right_points:
                    cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)

                # EAR ì„ê³„ê°’ ì„¤ì •
                EAR_THRESHOLD = 0.21 
                # ìŠ¤íŒŒë¥´íƒ€ ëª¨ë“œ(ë§¤ìš° ì§§ì€ í—ˆìš© ì‹œê°„)ì—ì„œëŠ” EAR ì„ê³„ê°’ì„ ë†’ì—¬ ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘
                if st.session_state.EYE_CLOSED_TIME_SEC <= 1.0: 
                     EAR_THRESHOLD = 0.25 
                    
                if current_ear > EAR_THRESHOLD:
                    eyes_open = True
                    eyes_closed_time = 0.0
                else:
                    eyes_open = False
                    eyes_closed_time += dt

                if eyes_open:
                    stop_alarm()
                    state = "FOCUS"
                    st.session_state.focused_time += dt
                else:
                    if eyes_closed_time >= st.session_state.EYE_CLOSED_TIME_SEC:
                        state = "DROWSY"
                        play_alarm(now, eyes_closed_time, st.session_state.EYE_CLOSED_TIME_SEC)
                        st.session_state.drowsy_time += dt
                    else:
                        state = "BLINK / WARNING"

            else:
                current_ear = 0.0
                eyes_closed_time = 0.0
                no_face_time += dt
                stop_alarm()

                NO_FACE_THRESHOLD = 5.0
                if no_face_time >= NO_FACE_THRESHOLD:
                    state = "AWAY"
                else:
                    state = "LOST"

            # í™”ë©´ì— ìƒíƒœ/ì‹œê°„ í‘œì‹œ
            status_text = f"State: {state} | EAR: {current_ear:.3f} | EyesClosed: {eyes_closed_time:.1f}s"
            if state == "DROWSY":
                status_color = (0, 0, 255) # Red (BGR)
            elif state == "AWAY":
                status_color = (0, 165, 255) # Orange
            elif state == "FOCUS":
                status_color = (0, 255, 0) # Green
            else:
                status_color = (255, 255, 255) # White

            cv2.putText(
                frame,
                status_text,
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                status_color,
                2,
            )
            
            # ê²½ê³  ì œê±°: use_column_width -> use_container_width
            webcam_placeholder.image(frame, channels="BGR", use_container_width=True)
            status_placeholder.text(
                f"ì§‘ì¤‘ ì‹œê°„: {format_time(st.session_state.focused_time)} | "
                f"ì¡¸ìŒ/ì´ì„ ì‹œê°„: {format_time(st.session_state.drowsy_time + no_face_time)} | "
                f"ë¯¼ê°ë„(ëˆˆ ê°ìŒ í—ˆìš© ì‹œê°„): {st.session_state.EYE_CLOSED_TIME_SEC}ì´ˆ"
            )

            time.sleep(0.01)

        # ê³µë¶€ ì¢…ë£Œ ì‹œ í†µê³„ ì¶œë ¥ (ë°˜ë³µë¬¸ ì¢…ë£Œ í›„ ì‹¤í–‰)
       # =======================
# ê³µë¶€ ì¢…ë£Œ ì‹œ í†µê³„ ì¶œë ¥
# =======================
if not st.session_state.study_started and st.session_state.total_elapsed_time > 0:

    st.markdown("<h3 style='text-align: center;'>ğŸ“Š ê³µë¶€ ê²°ê³¼</h3>", unsafe_allow_html=True)

    total_time = st.session_state.total_elapsed_time
    focus_time = st.session_state.focused_time
    drowsy_time = total_time - focus_time

    st.write(f"**ì´ ê³µë¶€ ì‹œê°„:** {format_time(total_time)}")
    st.write(f"**ì§‘ì¤‘ ì‹œê°„:** {format_time(focus_time)}")
    st.write(f"**ì¡¸ìŒ/ì´ì„ ì‹œê°„:** {format_time(drowsy_time)}")

    if total_time > 0:
        focus_ratio = (focus_time / total_time) * 100
        st.progress(focus_ratio / 100)
        st.write(f"**ì§‘ì¤‘ë„:** {focus_ratio:.1f}%")

    # ë‹¤ì‹œ ì‹œì‘í•˜ê¸° ë²„íŠ¼
    if st.button("ìƒˆë¡œìš´ ê³µë¶€ ì‹œì‘"):
        st.session_state.clear()
        st.rerun()
# ì›¹ìº ì´ ì‹¤ì œë¡œ ì—´ë ¸ì„ ë•Œë§Œ release() ì‹¤í–‰
try:
    if 'cap' in locals() or 'cap' in globals():
        cap.release()
except:
    pass

cv2.destroyAllWindows()

    
    # ë””ì½”ë”©ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ (ì„ íƒ ì‚¬í•­)
if os.path.exists(ALARM_WAV_FILENAME):
        try:
            os.remove(ALARM_WAV_FILENAME)
        except PermissionError:
            # Pygameì´ íŒŒì¼ì„ ë†“ì•„ì£¼ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            pass


st.markdown("""
    <div class="footer">
        Â© 2025 9ì¡° (Team 9)
    </div>
""", unsafe_allow_html=True)
