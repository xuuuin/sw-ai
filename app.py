import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
import math
import time
from streamlit_webrtc import VideoTransformerBase, webrtc_streamer # <-- ìˆ˜ì •: webrtc_stream -> webrtc_streamer
import threading
from streamlit.components.v1 import html

# ========================
# 1. ìƒìˆ˜ ë° ì„¤ì •
# ========================

# StudyCam ì•± ìƒíƒœ ì •ì˜
APP_STATE_SETUP = "SETUP"
APP_STATE_MONITORING = "MONITORING"
APP_STATE_PAUSED = "PAUSED"
APP_STATE_ENDED = "ENDED"

# ì¡¸ìŒ ê°ì§€ ê¸°ì¤€
EYE_CLOSED_THRESHOLD = 0.21 
NO_FACE_THRESHOLD = 5.0     

# ë¯¼ê°ë„ ë‹¨ê³„ ì„¤ì •
SENSITIVITY_MAP = {
    1: {"label": "ğŸ˜´ 1ë‹¨ê³„ (í”¼ê³¤í•´ìš”)", "time": 5.0},
    2: {"label": "ğŸ˜ 2ë‹¨ê³„ (ë³´í†µì´ì—ìš”)", "time": 3.0},
    3: {"label": "ğŸ˜¤ 3ë‹¨ê³„ (ì§‘ì¤‘í• ë˜ìš”)", "time": 2.0},
    4: {"label": "ğŸ”¥ 4ë‹¨ê³„ (ìŠ¤íŒŒë¥´íƒ€)", "time": 1.0}
}

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils

# ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (FaceMesh ê¸°ì¤€)
LEFT_EYE_IDX  = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]

# --- ì˜¤ë””ì˜¤ ì„¤ì • ---
# Base64 ì¸ì½”ë”©ëœ ë”ë¯¸ WAV íŒŒì¼ (ê²½ê³ ìŒ)
# ì‹¤ì œ ì•ŒëŒ ì†Œë¦¬("ì‚¬ë‹¹ë¡œ.wav")ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ í•´ë‹¹ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì—¬ê¸°ì— ë„£ì–´ì£¼ì„¸ìš”.
BASE64_SOUND = "data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQQAAAAAAABeLwE6+QnO9h7k+P/4/PPw5O3s8uTk3tvPz4+40Qy3XQ4l+QAA"


def play_alarm_js():
    """HTML ì˜¤ë””ì˜¤ íƒœê·¸ë¥¼ ì‚½ì…í•˜ì—¬ ê²½ê³ ìŒì„ ì¬ìƒí•©ë‹ˆë‹¤."""
    # JavaScriptë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ê³  ì¦‰ì‹œ HTMLì„ ì œê±° (ê¹¨ë—í•˜ê²Œ)
    audio_html = f"""
    <audio id="alarm-sound" autoplay>
        <source src="{BASE64_SOUND}" type="audio/wav">
        Your browser does not support the audio element.
    </audio>
    <script>
        var audio = document.getElementById('alarm-sound');
        if (audio) {{
            audio.volume = 0.5; // ë³¼ë¥¨ ì„¤ì •
            audio.play().catch(e => console.error("Audio playback blocked:", e));
            // ì¬ìƒ í›„ ìš”ì†Œ ì œê±° (Streamlit ì¬ì‹¤í–‰ ì‹œë§ˆë‹¤ ë‹¤ì‹œ ì‚½ì…)
            setTimeout(() => {{ 
                var element = document.getElementById('alarm-sound'); 
                if(element) element.remove(); 
            }}, 2000); 
        }}
    </script>
    """
    # Streamlitì— HTML ì½”ë“œ ì‚½ì…
    st.markdown(audio_html, unsafe_allow_html=True)

# ========================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ========================

def format_time(sec):
    """ì‹œê°„ì„ 'MM:SS' í˜•ì‹ìœ¼ë¡œ í¬ë§·"""
    m = int(sec // 60)
    s = int(sec % 60)
    return f"{m:02d}:{s:02d}"

def calc_EAR(landmarks, eye_idx_list, img_w, img_h):
    """ëˆˆ ëœë“œë§ˆí¬ ì¢Œí‘œë¡œ EAR ê³„ì‚°"""
    points = []
    for idx in eye_idx_list:
        lm = landmarks[idx]
        x = int(lm.x * img_w)
        y = int(lm.y * img_h)
        points.append((x, y))
    
    # p1, p2, p3, p4, p5, p6
    p1, p2, p3, p4, p5, p6 = points

    def dist(a, b):
        return math.hypot(a[0] - b[0], a[1] - b[1])

    # ìˆ˜ì§ ê±°ë¦¬ì™€ ìˆ˜í‰ ê±°ë¦¬ ë¹„ìœ¨ ê³„ì‚°
    ear = (dist(p2, p6) + dist(p3, p5)) / (2.0 * dist(p1, p4) + 1e-6)
    return ear, points

# ========================
# 3. Streamlit Session State ì´ˆê¸°í™”
# ========================

if 'app_state' not in st.session_state:
    # ì•± ìƒíƒœ
    st.session_state.app_state = APP_STATE_SETUP
    
    # ì„¤ì • ê°’
    st.session_state.study_goal = ""
    st.session_state.sensitivity_level = 2 # ê¸°ë³¸ 2ë‹¨ê³„
    st.session_state.eye_closed_time_sec = SENSITIVITY_MAP[2]["time"]
    
    # ì‹œê°„ ë° ìƒíƒœ ëˆ„ì  ë³€ìˆ˜
    st.session_state.session_start = 0.0
    st.session_state.focused_time = 0.0
    st.session_state.drowsy_time = 0.0
    st.session_state.away_time = 0.0
    st.session_state.last_update_time = 0.0 # dt ê³„ì‚°ìš©
    
    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°’
    st.session_state.drowsiness_state = "INIT"
    st.session_state.eyes_closed_time = 0.0
    st.session_state.no_face_time = 0.0
    st.session_state.current_ear = 0.0
    st.session_state.alarm_active = False
    # ì•ŒëŒ ì¬ìƒì„ í•œ ë²ˆë§Œ í•˜ê¸° ìœ„í•œ í”Œë˜ê·¸
    st.session_state.alarm_played_in_cycle = False 

# ========================
# 4. VideoTransformer (MediaPipe ì²˜ë¦¬)
# ========================

class FaceMeshDrowsinessTransformer(VideoTransformerBase):
    """ì›¹ìº  í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ê³  ì¡¸ìŒ ìƒíƒœë¥¼ ê°ì§€í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # MediaPipe FaceMeshëŠ” ì¸ìŠ¤í„´ìŠ¤ë§ˆë‹¤ í•˜ë‚˜ì”© ìƒì„±
        self.face_mesh = mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
        )
        # ë½ (Lock) ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ session_state ì ‘ê·¼ ì‹œ ë™ì‹œì„± ë¬¸ì œ ë°©ì§€
        self.lock = threading.Lock()

    def transform(self, frame: np.ndarray) -> np.ndarray:
        # Streamlit session state ë³µì‚¬ (í”„ë ˆì„ ë‹¨ìœ„ ìƒíƒœ ì—…ë°ì´íŠ¸)
        with self.lock:
            state = st.session_state.app_state
            last_update_time = st.session_state.last_update_time
            eye_closed_time_sec = st.session_state.eye_closed_time_sec
            eyes_closed_time = st.session_state.eyes_closed_time
            no_face_time = st.session_state.no_face_time
            
        img = frame.copy()
        img_h, img_w, _ = img.shape
        now = time.time()
        
        # dt ê³„ì‚°
        dt = 0.0
        if last_update_time != 0.0:
            dt = now - last_update_time

        # ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì‹œê°„ ëˆ„ì ì€ MONITORING ìƒíƒœì—ì„œë§Œ ì§„í–‰
        if state == APP_STATE_MONITORING:
            
            # MediaPipe ì²˜ë¦¬
            rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb)
            
            current_ear = 0.0
            drowsiness_state = "LOST (ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨)"
            alarm_active = False
            
            if results.multi_face_landmarks:
                face_landmarks = results.multi_face_landmarks[0].landmark

                # EAR ê³„ì‚°
                left_ear, _ = calc_EAR(face_landmarks, LEFT_EYE_IDX, img_w, img_h)
                right_ear, _ = calc_EAR(face_landmarks, RIGHT_EYE_IDX, img_w, img_h)
                current_ear = (left_ear + right_ear) / 2.0
                
                # ì¡¸ìŒ ê°ì§€ ë¡œì§
                if current_ear > EYE_CLOSED_THRESHOLD:
                    eyes_closed_time = 0.0
                    drowsiness_state = "FOCUS (ì§‘ì¤‘)"
                    st.session_state.focused_time += dt
                else:
                    eyes_closed_time += dt
                    
                    if eyes_closed_time >= eye_closed_time_sec:
                        drowsiness_state = "DROWSY (ì¡¸ìŒ ê°ì§€!)"
                        st.session_state.drowsy_time += dt
                        alarm_active = True
                        
                        # ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬ í‘œì‹œ (ì‹œê°ì  ì•ŒëŒ)
                        cv2.rectangle(img, (0, 0), (img_w, img_h), (0, 0, 255), 10) 
                    else:
                        drowsiness_state = "BLINK / WARNING (ê²½ê³ )"

                no_face_time = 0.0
                
            else:
                # ì–¼êµ´ ì•ˆ ë³´ì„
                eyes_closed_time = 0.0
                no_face_time += dt
                
                if no_face_time >= NO_FACE_THRESHOLD:
                    drowsiness_state = "AWAY (ìë¦¬ ë¹„ì›€)"
                    st.session_state.away_time += dt
                    # íŒŒë€ìƒ‰ í…Œë‘ë¦¬ í‘œì‹œ
                    cv2.rectangle(img, (0, 0), (img_w, img_h), (255, 100, 100), 10)
                else:
                    drowsiness_state = "LOST (ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨)"
            
            # --- ìƒíƒœ ì—…ë°ì´íŠ¸ (Lock ì‚¬ìš©) ---
            with self.lock:
                st.session_state.last_update_time = now
                st.session_state.current_ear = current_ear
                st.session_state.eyes_closed_time = eyes_closed_time
                st.session_state.no_face_time = no_face_time
                st.session_state.drowsiness_state = drowsiness_state
                st.session_state.alarm_active = alarm_active
        
        # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
        cv2.putText(img, f"State: {st.session_state.drowsiness_state}", 
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        if st.session_state.alarm_active:
             cv2.putText(img, "ğŸš¨ ALARM! (ì†Œë¦¬ í™œì„±í™”)", (img_w // 2 - 250, img_h // 2), 
                         cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)

        # BGR í”„ë ˆì„ ë°˜í™˜
        return img

# ========================
# 5. Streamlit UI ë Œë”ë§ í•¨ìˆ˜
# ========================

def render_setup_ui():
    """ì´ˆê¸° ì„¤ì • í™”ë©´"""
    st.title("StudyCam: ëŒ€í™”í˜• í•™ìŠµ ëª¨ë‹ˆí„°ë§")
    st.write("---")
    
    st.markdown("## ì˜¤ëŠ˜ì˜ ê³µë¶€ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”? ğŸ¯")
    goal = st.text_input("ëª©í‘œ ì…ë ¥", value="íŒŒì´ì¬ í”„ë¡œì íŠ¸ ì™„ì„±í•˜ê¸°", label_visibility="collapsed")
    
    st.markdown("## í˜„ì¬ ì»¨ë””ì…˜ì— ë§ëŠ” ì§‘ì¤‘ ëª¨ë“œ(ë¯¼ê°ë„)ë¥¼ ì„ íƒí•˜ì„¸ìš” â­")
    
    sensitivity_options = [SENSITIVITY_MAP[k]["label"] for k in sorted(SENSITIVITY_MAP.keys())]
    selected_label = st.radio(
        "ê°ì§€ ê°•ë„ ì„ íƒ",
        options=sensitivity_options,
        index=1, 
        help="ëˆˆ ê°ìŒ í—ˆìš© ì‹œê°„ì´ ì§§ì„ìˆ˜ë¡ ì—„ê²©í•œ ëª¨ë“œì…ë‹ˆë‹¤."
    )
    
    selected_level = next(k for k, v in SENSITIVITY_MAP.items() if v["label"] == selected_label)

    st.markdown("---")
    
    if st.button("ğŸš€ ê³µë¶€ ì‹œì‘í•˜ê¸°", use_container_width=True, type="primary", key="start_study_btn"):
        st.session_state.study_goal = goal
        st.session_state.sensitivity_level = selected_level
        st.session_state.eye_closed_time_sec = SENSITIVITY_MAP[selected_level]["time"]
        st.session_state.app_state = APP_STATE_MONITORING
        st.session_state.session_start = time.time()
        st.session_state.last_update_time = time.time()
        st.rerun()

def handle_pause_resume():
    """ì¼ì‹œì •ì§€/ì¬ê°œ ìƒíƒœ ë³€ê²½ ë° ì‹œê°„ ì¡°ì •"""
    if st.session_state.app_state == APP_STATE_MONITORING:
        st.session_state.app_state = APP_STATE_PAUSED
        st.session_state.last_update_time = time.time()
    elif st.session_state.app_state == APP_STATE_PAUSED:
        st.session_state.app_state = APP_STATE_MONITORING
        pause_duration = time.time() - st.session_state.last_update_time
        st.session_state.session_start += pause_duration
        st.session_state.last_update_time = time.time()
    st.rerun()

def handle_end_session():
    """ì„¸ì…˜ì„ ì¢…ë£Œí•˜ê³  í†µê³„ í™”ë©´ìœ¼ë¡œ ì „í™˜"""
    if st.session_state.app_state != APP_STATE_ENDED:
        if st.session_state.app_state == APP_STATE_MONITORING:
            st.session_state.last_update_time = time.time()
        
        st.session_state.app_state = APP_STATE_ENDED
        st.rerun()

def render_monitoring_ui():
    """ëª¨ë‹ˆí„°ë§ ë° í•™ìŠµ ì§„í–‰ í™”ë©´"""
    
    # 1. ì•ŒëŒ ì¬ìƒ ë¡œì§
    # ì¡¸ìŒ ê°ì§€ ì‹œ, í•œ ë²ˆë§Œ ì•ŒëŒ ì†Œë¦¬ ì¬ìƒì„ ì‹œë„í•©ë‹ˆë‹¤.
    if st.session_state.alarm_active and not st.session_state.alarm_played_in_cycle:
        play_alarm_js()
        st.session_state.alarm_played_in_cycle = True
    elif not st.session_state.alarm_active:
        st.session_state.alarm_played_in_cycle = False


    st.title("StudyCam: ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§ ì¤‘")
    st.markdown(f"## ğŸ¯ ëª©í‘œ: **{st.session_state.study_goal}**")

    # ìƒë‹¨ ì •ë³´ ìš”ì•½
    col_status, col_ear, col_sensitivity = st.columns([2, 1, 1])
    
    elapsed_time = time.time() - st.session_state.session_start if st.session_state.app_state != APP_STATE_PAUSED else st.session_state.last_update_time - st.session_state.session_start
    
    status_text = st.session_state.drowsiness_state
    if st.session_state.app_state == APP_STATE_PAUSED:
        status_text = "ì¼ì‹œ ì •ì§€ë¨ (PAUSED)"

    col_status.metric(
        "â³ ì´ í•™ìŠµ ì‹œê°„", 
        format_time(elapsed_time), 
        delta=status_text, 
        delta_color="off" if "FOCUS" in st.session_state.drowsiness_state else "inverse"
    )
    col_ear.metric("EAR", f"{st.session_state.current_ear:.3f}")
    col_sensitivity.metric(
        "ë¯¼ê°ë„", 
        f"{st.session_state.sensitivity_level}ë‹¨ê³„", 
        f"{st.session_state.eye_closed_time_sec:.1f}ì´ˆ í—ˆìš©"
    )
    
    st.markdown("---")

    # ì›¹ìº  ìŠ¤íŠ¸ë¦¼ (PIP ì—­í• )
    st.subheader("ì›¹ìº  ëª¨ë‹ˆí„°ë§ (ì¡¸ìŒ/ìë¦¬ ë¹„ì›€ ê°ì§€)")
    webrtc_streamer( # <-- ìˆ˜ì •: webrtc_stream -> webrtc_streamer
        key="drowsiness_monitor",
        video_processor_factory=FaceMeshDrowsinessTransformer,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={
            "video": {
                "width": {"ideal": 1280},
                "height": {"ideal": 720},
                "frameRate": {"ideal": 30}
            },
            "audio": False
        },
        async_transform=True,
    )

    # ì‹¤ì‹œê°„ ìƒíƒœ ë° ëˆ„ì  ì‹œê°„
    st.markdown("### ì‹¤ì‹œê°„ ê°ì§€ ìƒíƒœ ë° ëˆ„ì  ì‹œê°„")
    st.text(f"  ì§‘ì¤‘ ì‹œê°„: {format_time(st.session_state.focused_time)}")
    st.text(f"  ì¡¸ìŒ ì‹œê°„: {format_time(st.session_state.drowsy_time)}")
    st.text(f"  ìë¦¬ ë¹„ì›€ ì‹œê°„: {format_time(st.session_state.away_time)}")

    # ë²„íŠ¼
    st.markdown("---")
    col_pause, col_end = st.columns(2)
    
    # ì¼ì‹œì •ì§€ / ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼
    if st.session_state.app_state == APP_STATE_MONITORING:
        pause_label = "â¸ï¸ ì ì‹œ ë©ˆì¶¤"
        pause_type = "secondary"
        if col_pause.button(pause_label, use_container_width=True, type=pause_type, key="pause_btn_active"):
            handle_pause_resume()
    else: # APP_STATE_PAUSED
        pause_label = "â–¶ï¸ ë‹¤ì‹œ ì‹œì‘"
        pause_type = "primary"
        if col_pause.button(pause_label, use_container_width=True, type=pause_type, key="resume_btn_active"):
            handle_pause_resume()
            
    # ê³µë¶€ ì¢…ë£Œ ë²„íŠ¼
    if col_end.button("ğŸ›‘ ê³µë¶€ ì¢…ë£Œ", use_container_width=True, type="primary", key="end_session_btn"):
        handle_end_session()

def render_ended_ui():
    """ìµœì¢… í•™ìŠµ í†µê³„ í™”ë©´"""
    st.title("StudyCam: í•™ìŠµ ê²°ê³¼ ìš”ì•½ ğŸ“")
    st.markdown("---")
    
    # ì´ í•™ìŠµ ì‹œê°„ = ì„¸ì…˜ ì¢…ë£Œ ì‹œì  - ì„¸ì…˜ ì‹œì‘ ì‹œì  (ì¼ì‹œì •ì§€ ì‹œê°„ í¬í•¨)
    total_session_time = st.session_state.last_update_time - st.session_state.session_start
    # ì´ í™œë™ ì‹œê°„ = ì§‘ì¤‘ + ì¡¸ìŒ + ìë¦¬ ë¹„ì›€
    total_active_time = st.session_state.focused_time + st.session_state.drowsy_time + st.session_state.away_time
    
    # ì§‘ì¤‘ë„ ê³„ì‚°
    focus_ratio = (st.session_state.focused_time / total_active_time) * 100 if total_active_time > 0 else 0
    
    st.markdown(f"## ğŸ¯ ëª©í‘œ: {st.session_state.study_goal}")
    st.markdown(f"**â­ ë¯¼ê°ë„ ì„¤ì •:** {st.session_state.sensitivity_level}ë‹¨ê³„ ({st.session_state.eye_closed_time_sec:.1f}ì´ˆ í—ˆìš©)")
    st.markdown("---")

    # í†µê³„ ë©”íŠ¸ë¦­
    st.metric("ì´ ì„¸ì…˜ ì‹œê°„", format_time(total_session_time))
    st.metric("âœ… ìµœì¢… ì§‘ì¤‘ë„", f"{focus_ratio:.1f}%")

    st.markdown("### ìƒì„¸ ì‹œê°„ ë¶„ì„")
    
    col_f, col_d, col_a = st.columns(3)
    col_f.metric("ì§‘ì¤‘ ì‹œê°„", format_time(st.session_state.focused_time))
    col_d.metric("ì¡¸ìŒ ì‹œê°„", format_time(st.session_state.drowsy_time))
    col_a.metric("ìë¦¬ ë¹„ì›€ ì‹œê°„", format_time(st.session_state.away_time))

    st.markdown("---")
    
    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True, key="reset_btn"):
        # ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.app_state = APP_STATE_SETUP
        st.session_state.session_start = 0.0
        st.session_state.focused_time = 0.0
        st.session_state.drowsy_time = 0.0
        st.session_state.away_time = 0.0
        st.session_state.last_update_time = 0.0
        st.rerun()

# ========================
# 6. ë©”ì¸ ì•± ì‹¤í–‰
# ========================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    st.set_page_config(
        page_title="StudyCam Drowsiness Monitor (íŒ€ 9ì¡°)",
        layout="wide",
        initial_sidebar_state="collapsed",
    )
    # st.sidebar.markdown("Â© 2025 sw_ai 9ì¡° (Team 9)")
    
    if st.session_state.app_state == APP_STATE_SETUP:
        render_setup_ui()
    elif st.session_state.app_state == APP_STATE_MONITORING or st.session_state.app_state == APP_STATE_PAUSED:
        render_monitoring_ui()
    elif st.session_state.app_state == APP_STATE_ENDED:
        render_ended_ui()

if __name__ == "__main__":
    main()