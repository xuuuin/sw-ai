import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
import math
import time
import threading

from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av

# ========================
# 1. ìƒìˆ˜ ë° ì„¤ì •
# ========================

APP_STATE_SETUP = "SETUP"
APP_STATE_MONITORING = "MONITORING"
APP_STATE_PAUSED = "PAUSED"
APP_STATE_ENDED = "ENDED"

EYE_CLOSED_THRESHOLD = 0.21
NO_FACE_THRESHOLD = 5.0

APP_STATE_IDLE = "IDLE"
APP_STATE_MONITORING = "MONITORING"

def init_session_state():
    """ì¡¸ìŒ ê°ì§€ì— í•„ìš”í•œ ìƒíƒœ ê°’ë“¤ì„ í•œ ë²ˆì— ì´ˆê¸°í™”"""
    defaults = {
        "app_state": APP_STATE_IDLE,       # ì²˜ìŒì—ëŠ” ëŒ€ê¸° ìƒíƒœ
        "last_update_time": 0.0,
        "eye_closed_time_sec": 2.0,        # ëˆˆ ê°ì€ ì‹œê°„ ì„ê³„ê°’(ì´ˆ)
        "eyes_closed_time": 0.0,
        "no_face_time": 0.0,
        "current_ear": 0.0,
        "drowsiness_state": "INIT",
        "alarm_active": False,
        "focused_time": 0.0,
        "drowsy_time": 0.0,
        "away_time": 0.0,
    }

    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

SENSITIVITY_MAP = {
    1: {"label": "ğŸ˜´ 1ë‹¨ê³„ (í”¼ê³¤í•´ìš”)", "time": 5.0},
    2: {"label": "ğŸ˜ 2ë‹¨ê³„ (ë³´í†µì´ì—ìš”)", "time": 3.0},
    3: {"label": "ğŸ˜¤ 3ë‹¨ê³„ (ì§‘ì¤‘í• ë˜ìš”)", "time": 2.0},
    4: {"label": "ğŸ”¥ 4ë‹¨ê³„ (ìŠ¤íŒŒë¥´íƒ€)", "time": 1.0},
}

mp_face_mesh = mp.solutions.face_mesh

LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]

BASE64_SOUND = (
    "data:audio/wav;base64,"
    "UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQQAAAAAAABeLwE6+QnO9h7k+P/4/PPw5O3s8uTk3tvPz4+40Qy3XQ4l+QAA"
)

def play_alarm_js(volume: float = 0.5):
    volume = max(0.0, min(1.0, volume))
    audio_html = f"""
    <audio id="alarm-sound" autoplay>
        <source src="{BASE64_SOUND}" type="audio/wav">
        Your browser does not support the audio element.
    </audio>
    <script>
        var audio = document.getElementById('alarm-sound');
        if (audio) {{
            audio.volume = {volume};
            audio.play().catch(e => console.error("Audio playback blocked:", e));
            setTimeout(() => {{
                var element = document.getElementById('alarm-sound');
                if(element) element.remove();
            }}, 2000);
        }}
    </script>
    """
    st.markdown(audio_html, unsafe_allow_html=True)

# ========================
# 2. ìœ í‹¸ í•¨ìˆ˜
# ========================

def format_time(sec: float) -> str:
    m = int(sec // 60)
    s = int(sec % 60)
    return f"{m:02d}:{s:02d}"

def calc_EAR(landmarks, eye_idx_list, img_w, img_h):
    points = []
    for idx in eye_idx_list:
        lm = landmarks[idx]
        x = int(lm.x * img_w)
        y = int(lm.y * img_h)
        points.append((x, y))

    p1, p2, p3, p4, p5, p6 = points

    def dist(a, b):
        return math.hypot(a[0] - b[0], a[1] - b[1])

    ear = (dist(p2, p6) + dist(p3, p5)) / (2.0 * dist(p1, p4) + 1e-6)
    return ear, points

# ========================
# 3. session_state ì´ˆê¸°í™”
# ========================

if "app_state" not in st.session_state:
    st.session_state.app_state = APP_STATE_SETUP

    st.session_state.study_goal = ""
    st.session_state.sensitivity_level = 2
    st.session_state.eye_closed_time_sec = SENSITIVITY_MAP[2]["time"]

    st.session_state.session_start = 0.0
    st.session_state.focused_time = 0.0
    st.session_state.drowsy_time = 0.0
    st.session_state.away_time = 0.0
    st.session_state.last_update_time = 0.0

    st.session_state.drowsiness_state = "INIT"
    st.session_state.eyes_closed_time = 0.0
    st.session_state.no_face_time = 0.0
    st.session_state.current_ear = 0.0
    st.session_state.alarm_active = False
    st.session_state.alarm_played_in_cycle = False

# ========================
# 4. VideoProcessor (MediaPipe + EAR)
# ========================

class FaceMeshDrowsinessProcessor(VideoProcessorBase):
    def __init__(self):
        self.face_mesh = mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
        )
        self.lock = threading.Lock()

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        try:
            img = frame.to_ndarray(format="bgr24")
            img_h, img_w, _ = img.shape
            now = time.time()

            with self.lock:
                state = st.session_state.get("app_state", APP_STATE_IDLE)
                last_update_time = st.session_state.get("last_update_time", 0.0)
                eye_closed_time_sec = st.session_state.get("eye_closed_time_sec", 2.0)
                eyes_closed_time = st.session_state.get("eyes_closed_time", 0.0)
                no_face_time = st.session_state.get("no_face_time", 0.0)

            dt = 0.0
            if last_update_time != 0.0:
                dt = now - last_update_time

            current_ear = st.session_state.current_ear
            drowsiness_state = st.session_state.drowsiness_state
            alarm_active = False

            if state == APP_STATE_MONITORING:
                rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                results = self.face_mesh.process(rgb)

                if results.multi_face_landmarks:
                    face_landmarks = results.multi_face_landmarks[0].landmark

                    left_ear, _ = calc_EAR(face_landmarks, LEFT_EYE_IDX, img_w, img_h)
                    right_ear, _ = calc_EAR(face_landmarks, RIGHT_EYE_IDX, img_w, img_h)
                    current_ear = (left_ear + right_ear) / 2.0

                    if current_ear > EYE_CLOSED_THRESHOLD:
                        eyes_closed_time = 0.0
                        drowsiness_state = "FOCUS (ì§‘ì¤‘)"
                        st.session_state.focused_time += dt
                    else:
                        eyes_closed_time += dt
                        if eyes_closed_time >= eye_closed_time_sec:
                            drowsiness_state = "DROWSY (ì¡¸ìŒ ê°ì§€!)"
                            st.session_state.drowsy_time += dt
                            alarm_active = True
                            cv2.rectangle(img, (0, 0), (img_w, img_h), (0, 0, 255), 10)
                        else:
                            drowsiness_state = "BLINK / WARNING (ê²½ê³ )"

                    no_face_time = 0.0
                else:
                    eyes_closed_time = 0.0
                    no_face_time += dt
                    if no_face_time >= NO_FACE_THRESHOLD:
                        drowsiness_state = "AWAY (ìë¦¬ ë¹„ì›€)"
                        st.session_state.away_time += dt
                        cv2.rectangle(img, (0, 0), (img_w, img_h), (255, 100, 100), 10)
                    else:
                        drowsiness_state = "LOST (ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨)"

                with self.lock:
                    st.session_state.last_update_time = now
                    st.session_state.current_ear = current_ear
                    st.session_state.eyes_closed_time = eyes_closed_time
                    st.session_state.no_face_time = no_face_time
                    st.session_state.drowsiness_state = drowsiness_state
                    st.session_state.alarm_active = alarm_active

            cv2.putText(
                img,
                f"State: {st.session_state.drowsiness_state}",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 255),
                2,
            )

            if st.session_state.alarm_active:
                cv2.putText(
                    img,
                    "ğŸš¨ ALARM! (ì†Œë¦¬ í™œì„±í™”)",
                    (img_w // 2 - 250, img_h // 2),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1.2,
                    (0, 0, 255),
                    3,
                )

            return av.VideoFrame.from_ndarray(img, format="bgr24")

        except Exception as e:
            print("ERROR in recv:", repr(e))
            # ì—ëŸ¬ ë‚˜ë„ ìŠ¤íŠ¸ë¦¼ì´ ì™„ì „ ì£½ì§€ ì•Šê²Œ ì›ë³¸ í”„ë ˆì„ ë°˜í™˜
            return frame
    
    

# ========================
# 5. UI í•¨ìˆ˜ë“¤
# ========================

def render_setup_ui():
    st.title("StudyCam: ëŒ€í™”í˜• í•™ìŠµ ëª¨ë‹ˆí„°ë§")
    st.write("---")

    st.markdown("## ì˜¤ëŠ˜ì˜ ê³µë¶€ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”? ğŸ¯")
    goal = st.text_input("ëª©í‘œ ì…ë ¥", value="íŒŒì´ì¬ í”„ë¡œì íŠ¸ ì™„ì„±í•˜ê¸°", label_visibility="collapsed")

    st.markdown("## í˜„ì¬ ì»¨ë””ì…˜ì— ë§ëŠ” ì§‘ì¤‘ ëª¨ë“œ(ë¯¼ê°ë„)ë¥¼ ì„ íƒí•˜ì„¸ìš” â­")

    sensitivity_options = [SENSITIVITY_MAP[k]["label"] for k in sorted(SENSITIVITY_MAP.keys())]
    selected_label = st.radio(
        "ê°ì§€ ê°•ë„ ì„ íƒ",
        options=sensitivity_options,
        index=1,
        help="ëˆˆ ê°ìŒ í—ˆìš© ì‹œê°„ì´ ì§§ì„ìˆ˜ë¡ ì—„ê²©í•œ ëª¨ë“œì…ë‹ˆë‹¤.",
    )

    selected_level = next(k for k, v in SENSITIVITY_MAP.items() if v["label"] == selected_label)

    st.markdown("---")

    if st.button("ğŸš€ ê³µë¶€ ì‹œì‘í•˜ê¸°", use_container_width=True, type="primary", key="start_study_btn"):
        st.session_state.study_goal = goal
        st.session_state.sensitivity_level = selected_level
        st.session_state.eye_closed_time_sec = SENSITIVITY_MAP[selected_level]["time"]
        st.session_state.app_state = APP_STATE_MONITORING
        st.session_state.session_start = time.time()
        st.session_state.last_update_time = time.time()
        st.rerun()

def handle_pause_resume():
    if st.session_state.app_state == APP_STATE_MONITORING:
        st.session_state.app_state = APP_STATE_PAUSED
        st.session_state.last_update_time = time.time()
    elif st.session_state.app_state == APP_STATE_PAUSED:
        st.session_state.app_state = APP_STATE_MONITORING
        pause_duration = time.time() - st.session_state.last_update_time
        st.session_state.session_start += pause_duration
        st.session_state.last_update_time = time.time()
    st.rerun()

def handle_end_session():
    if st.session_state.app_state != APP_STATE_ENDED:
        if st.session_state.app_state == APP_STATE_MONITORING:
            st.session_state.last_update_time = time.time()
        st.session_state.app_state = APP_STATE_ENDED
        st.rerun()

def render_monitoring_ui():
    # ì•ŒëŒ ì¬ìƒ í•œ ë²ˆë§Œ
    if st.session_state.alarm_active and not st.session_state.alarm_played_in_cycle:
        extra = max(0.0, st.session_state.eyes_closed_time - st.session_state.eye_closed_time_sec)
        ratio = min(1.0, extra / 5.0)
        volume = 0.3 + (1.0 - 0.3) * ratio
        play_alarm_js(volume=volume)
        st.session_state.alarm_played_in_cycle = True
    elif not st.session_state.alarm_active:
        st.session_state.alarm_played_in_cycle = False

    st.title("StudyCam: ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§ ì¤‘")
    st.markdown(f"## ğŸ¯ ëª©í‘œ: **{st.session_state.study_goal}**")

    col_status, col_ear, col_sensitivity = st.columns([2, 1, 1])

    if st.session_state.session_start > 0:
        elapsed_time = time.time() - st.session_state.session_start
    else:
        elapsed_time = 0.0

    status_text = st.session_state.drowsiness_state
    if st.session_state.app_state == APP_STATE_PAUSED:
        status_text = "ì¼ì‹œ ì •ì§€ë¨ (PAUSED)"

    col_status.metric(
        "â³ ì´ í•™ìŠµ ì‹œê°„",
        format_time(elapsed_time),
        delta=status_text,
        delta_color="off" if "FOCUS" in st.session_state.drowsiness_state else "inverse",
    )
    col_ear.metric("EAR", f"{st.session_state.current_ear:.3f}")
    col_sensitivity.metric(
        "ë¯¼ê°ë„",
        f"{st.session_state.sensitivity_level}ë‹¨ê³„",
        f"{st.session_state.eye_closed_time_sec:.1f}ì´ˆ í—ˆìš©",
    )

    st.markdown("---")

    st.subheader("ì›¹ìº  ëª¨ë‹ˆí„°ë§ (ì¡¸ìŒ/ìë¦¬ ë¹„ì›€ ê°ì§€)")
    webrtc_streamer(
        key="drowsiness_monitor",
        video_processor_factory=FaceMeshDrowsinessProcessor,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={
            "video": {
                "width": {"ideal": 1280},
                "height": {"ideal": 720},
                "frameRate": {"ideal": 30},
            },
            "audio": False,
        },
        async_processing=True,
    )

    st.markdown("### ì‹¤ì‹œê°„ ê°ì§€ ìƒíƒœ ë° ëˆ„ì  ì‹œê°„")
    st.text(f"  ì§‘ì¤‘ ì‹œê°„: {format_time(st.session_state.focused_time)}")
    st.text(f"  ì¡¸ìŒ ì‹œê°„: {format_time(st.session_state.drowsy_time)}")
    st.text(f"  ìë¦¬ ë¹„ì›€ ì‹œê°„: {format_time(st.session_state.away_time)}")

    st.markdown("---")
    col_pause, col_end = st.columns(2)

    if st.session_state.app_state == APP_STATE_MONITORING:
        if col_pause.button("â¸ï¸ ì ì‹œ ë©ˆì¶¤", use_container_width=True, type="secondary", key="pause_btn_active"):
            handle_pause_resume()
    else:
        if col_pause.button("â–¶ï¸ ë‹¤ì‹œ ì‹œì‘", use_container_width=True, type="primary", key="resume_btn_active"):
            handle_pause_resume()

    if col_end.button("ğŸ›‘ ê³µë¶€ ì¢…ë£Œ", use_container_width=True, type="primary", key="end_session_btn"):
        handle_end_session()

def render_ended_ui():
    st.title("StudyCam: í•™ìŠµ ê²°ê³¼ ìš”ì•½ ğŸ“")
    st.markdown("---")

    total_session_time = st.session_state.last_update_time - st.session_state.session_start
    total_active_time = (
        st.session_state.focused_time
        + st.session_state.drowsy_time
        + st.session_state.away_time
    )
    focus_ratio = (
        (st.session_state.focused_time / total_active_time) * 100 if total_active_time > 0 else 0
    )

    st.markdown(f"## ğŸ¯ ëª©í‘œ: {st.session_state.study_goal}")
    st.markdown(
        f"**â­ ë¯¼ê°ë„ ì„¤ì •:** {st.session_state.sensitivity_level}ë‹¨ê³„ "
        f"({st.session_state.eye_closed_time_sec:.1f}ì´ˆ í—ˆìš©)"
    )
    st.markdown("---")

    st.metric("ì´ ì„¸ì…˜ ì‹œê°„", format_time(total_session_time))
    st.metric("âœ… ìµœì¢… ì§‘ì¤‘ë„", f"{focus_ratio:.1f}%")

    st.markdown("### ìƒì„¸ ì‹œê°„ ë¶„ì„")

    col_f, col_d, col_a = st.columns(3)
    col_f.metric("ì§‘ì¤‘ ì‹œê°„", format_time(st.session_state.focused_time))
    col_d.metric("ì¡¸ìŒ ì‹œê°„", format_time(st.session_state.drowsy_time))
    col_a.metric("ìë¦¬ ë¹„ì›€ ì‹œê°„", format_time(st.session_state.away_time))

    st.markdown("---")

    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True, key="reset_btn"):
        st.session_state.app_state = APP_STATE_SETUP
        st.session_state.session_start = 0.0
        st.session_state.focused_time = 0.0
        st.session_state.drowsy_time = 0.0
        st.session_state.away_time = 0.0
        st.session_state.last_update_time = 0.0
        st.rerun()

# ========================
# 6. ë©”ì¸
# ========================

def main():
    
    init_session_state()   # ğŸ”´ ì´ ì¤„ ì¶”ê°€!

    st.title("ì¡¸ìŒ ê°ì§€ AI ëª¨ë‹ˆí„°ë§")
    # ... ë²„íŠ¼/ìŠ¬ë¼ì´ë” ë“± UI ì½”ë“œ ...
    # webrtc_streamer(...) í˜¸ì¶œ ...
    st.set_page_config(
        page_title="StudyCam Drowsiness Monitor (íŒ€ 9ì¡°)",
        layout="wide",
        initial_sidebar_state="collapsed",
    )

    if st.session_state.app_state == APP_STATE_SETUP:
        render_setup_ui()
    elif st.session_state.app_state in (APP_STATE_MONITORING, APP_STATE_PAUSED):
        render_monitoring_ui()
    elif st.session_state.app_state == APP_STATE_ENDED:
        render_ended_ui()

if __name__ == "__main__":
    main()
