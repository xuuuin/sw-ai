import cv2
import time
import pygame
import numpy as np
import mediapipe as mp
import math

# ========================
# 1. Pygame Ï¥àÍ∏∞Ìôî & ÏïåÎûå
# ========================
pygame.mixer.init()
ALARM_SOUND = pygame.mixer.Sound("ÏÇ¨ÎãπÎ°ú.wav")

alarm_playing = False
last_alarm_time = 0.0
ALARM_INTERVAL = 1
BASE_VOLUME = 0.3          # ÏµúÏÜå Î≥ºÎ•®
MAX_VOLUME = 5.0           # ÏµúÎåÄ Î≥ºÎ•®
RAMP_DURATION = 2.0      # Î≥ºÎ•®Ïù¥ ÏµúÎåÄÏπòÏóê ÎèÑÎã¨ÌïòÎäî Îç∞ Í±∏Î¶¨Îäî ÏãúÍ∞Ñ(Ï¥à)


def play_alarm(now, eyes_closed_time):
    """
    Îàà Í∞êÏùÄ ÏãúÍ∞ÑÏù¥ Í∏∏Ïñ¥ÏßàÏàòÎ°ù Î≥ºÎ•®ÏùÑ ÌÇ§Ïö¥Îã§.
    eyes_closed_time: Îàà Í∞êÍ≥† ÏûàÎäî ÎàÑÏ†Å ÏãúÍ∞Ñ (Ï¥à)
    """
    global last_alarm_time

    # Ï°∏Ïùå Í∏∞Ï§Ä(EYE_CLOSED_TIME_SEC) Ïù¥ÌõÑÎ∂ÄÌÑ∞ Ï¶ùÍ∞ÄÎ∂Ñ Í≥ÑÏÇ∞
    extra = max(0.0, eyes_closed_time - EYE_CLOSED_TIME_SEC)

    # 0 ~ 1 ÏÇ¨Ïù¥ ÎπÑÏú®Î°ú ÏïïÏ∂ï (RAMP_DURATIONÏ¥à ÎèôÏïà ÏÑúÏÑúÌûà 0‚Üí1)
    ratio = min(1.0, extra / RAMP_DURATION)

    # BASE_VOLUME ~ MAX_VOLUME ÏÇ¨Ïù¥Î°ú Î≥¥Í∞Ñ
    volume = BASE_VOLUME + (MAX_VOLUME - BASE_VOLUME) * ratio
    volume = max(0.0, min(1.0, volume))  # ÏïàÏ†ÑÌïòÍ≤å 0~1Î°ú ÌÅ¥Îû®ÌîÑ

    # ÏùºÏ†ï Í∞ÑÍ≤©ÎßàÎã§Îßå Ïö∏Î¶¨Í≤å ÌïòÍ∏∞
    if now - last_alarm_time >= ALARM_INTERVAL:
        ALARM_SOUND.stop()
        ALARM_SOUND.set_volume(volume)   # üîä Ïó¨Í∏∞ÏÑú Î≥ºÎ•® ÏÑ§Ï†ï
        ALARM_SOUND.play()
        last_alarm_time = now

def stop_alarm():
    global alarm_playing
    if alarm_playing:
        ALARM_SOUND.stop()
        alarm_playing = False

# ========================
# 2. MediaPipe Ï§ÄÎπÑ
# ========================
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils

# Îàà ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ (FaceMesh Í∏∞Ï§Ä)
LEFT_EYE_IDX  = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]

def calc_EAR(landmarks, eye_idx_list, img_w, img_h):
    """Îàà ÎûúÎìúÎßàÌÅ¨ Ï¢åÌëúÎ°ú EAR Í≥ÑÏÇ∞"""
    points = []
    for idx in eye_idx_list:
        lm = landmarks[idx]
        x = int(lm.x * img_w)
        y = int(lm.y * img_h)
        points.append((x, y))
    # p1, p2, p3, p4, p5, p6
    p1, p2, p3, p4, p5, p6 = points

    def dist(a, b):
        return math.hypot(a[0] - b[0], a[1] - b[1])

    ear = (dist(p2, p6) + dist(p3, p5)) / (2.0 * dist(p1, p4) + 1e-6)
    return ear, points

# ========================
# 3. ÏõπÏ∫† Ïó¥Í∏∞
# ========================
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("ÏõπÏ∫†ÏùÑ Ïó¥ Ïàò ÏóÜÏäµÎãàÎã§.")
    exit()

# ========================
# 4. ÏãúÍ∞Ñ / ÏÉÅÌÉú Î≥ÄÏàò
# ========================
EYE_CLOSED_THRESHOLD = 0.21   # EAR Ïù¥ Ïù¥ Í∞íÎ≥¥Îã§ ÏûëÏúºÎ©¥ Îàà Í∞êÏùÄ ÏÉÅÌÉúÎ°ú Í∞ÑÏ£º
EYE_CLOSED_TIME_SEC  = 1.0    # Ïù¥Î†áÍ≤å 1Ï¥à Ïù¥ÏÉÅ ÏßÄÏÜçÎêòÎ©¥ Ï°∏Ïùå
NO_FACE_THRESHOLD    = 5.0    # ÏñºÍµ¥ ÏóÜÏùå 5Ï¥à Ïù¥ÏÉÅÏù¥Î©¥ ÏûêÎ¶¨ÎπÑÏõÄ

eyes_closed_time = 0.0
no_face_time = 0.0
focused_time = 0.0

session_start = time.time()
prev_time = time.time()

state = "INIT"
current_ear = 0.0

print("q Î•º ÎàÑÎ•¥Î©¥ Ï¢ÖÎ£åÌï©ÎãàÎã§.")

# ========================
# 5. FaceMesh ÏÇ¨Ïö©
# ========================
with mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5,
) as face_mesh:

    while True:
        ret, frame = cap.read()
        if not ret:
            print("ÌîÑÎ†àÏûÑÏùÑ ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            break

        now = time.time()
        dt = now - prev_time
        prev_time = now

        frame = cv2.flip(frame, 1)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        img_h, img_w, _ = frame.shape

        results = face_mesh.process(rgb)

        face_detected = False
        eyes_open = False

        if results.multi_face_landmarks:
            face_detected = True
            no_face_time = 0.0  # ÏñºÍµ¥ Î≥¥Ïù¥Î©¥ Î¶¨ÏÖã

            face_landmarks = results.multi_face_landmarks[0].landmark

            # ÏôºÏ™Ω/Ïò§Î•∏Ï™Ω EAR Í≥ÑÏÇ∞
            left_ear, left_points = calc_EAR(face_landmarks, LEFT_EYE_IDX, img_w, img_h)
            right_ear, right_points = calc_EAR(face_landmarks, RIGHT_EYE_IDX, img_w, img_h)

            current_ear = (left_ear + right_ear) / 2.0

            # Îàà Ï£ºÎ≥Ä Ï†ê Ï∞çÏñ¥Î≥¥Í∏∞ (ÎîîÎ≤ÑÍ∑∏Ïö©)
            for (x, y) in left_points + right_points:
                cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)

            # EAR Í∏∞Ï§Ä Îàà Îú¨/Í∞êÍπÄ ÌåêÏ†ï
            if current_ear > EYE_CLOSED_THRESHOLD:
                eyes_open = True
                eyes_closed_time = 0.0
            else:
                eyes_open = False
                eyes_closed_time += dt

            # ÏÉÅÌÉú Í≤∞Ï†ï
            if eyes_open:
                stop_alarm()
                state = "FOCUS"
                focused_time += dt
            else:
                if eyes_closed_time >= EYE_CLOSED_TIME_SEC:
                    state = "DROWSY"
                    play_alarm(now, eyes_closed_time)
                else:
                    state = "BLINK / WARNING"

        else:
            # ÏñºÍµ¥ Ïïà Î≥¥ÏûÑ
            current_ear = 0.0
            eyes_closed_time = 0.0
            no_face_time += dt
            stop_alarm()

            if no_face_time >= NO_FACE_THRESHOLD:
                state = "AWAY"
            else:
                state = "LOST"

        # ========================
        # ÌôîÎ©¥Ïóê ÏÉÅÌÉú/ÏãúÍ∞Ñ ÌëúÏãú
        # ========================
        def format_time(sec):
            m = int(sec // 60)
            s = int(sec % 60)
            return f"{m:02d}:{s:02d}"

        elapsed = now - session_start

        cv2.putText(
            frame,
            f"State: {state}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            (0, 255, 255),
            2,
        )

        cv2.putText(
            frame,
            f"Session: {format_time(elapsed)}",
            (10, 60),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            2,
        )

        cv2.putText(
            frame,
            f"Focused: {format_time(focused_time)}",
            (10, 90),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (0, 200, 255),
            2,
        )

        cv2.putText(
            frame,
            f"EAR: {current_ear:.3f}",
            (10, 120),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (200, 200, 200),
            2,
        )

        cv2.putText(
            frame,
            f"EyesClosedTime: {eyes_closed_time:.1f}s",
            (10, 145),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (200, 200, 200),
            2,
        )

        cv2.imshow("StudyCam - MediaPipe Drowsiness Monitor", frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord("q"):
            break

# ========================
# 6. Ï¢ÖÎ£å Ï≤òÎ¶¨
# ========================
stop_alarm()
cap.release()
cv2.destroyAllWindows()

def format_time(sec):
    m = int(sec // 60)
    s = int(sec % 60)
    return f"{m:02d}:{s:02d}"

print("Ï¥ù ÏÑ∏ÏÖò ÏãúÍ∞Ñ:", format_time(time.time() - session_start))
print("ÏßëÏ§ë ÏãúÍ∞Ñ:", format_time(focused_time))